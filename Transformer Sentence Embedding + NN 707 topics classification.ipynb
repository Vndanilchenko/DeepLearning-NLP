{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "unexpected-encounter",
   "metadata": {},
   "source": [
    "## 707 topics classification using transformer based sentence embedding model \"all-mpnet-base-v2\" and custom NN architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-forwarding",
   "metadata": {},
   "source": [
    "Danilchenko Vadim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hollywood-consciousness",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib, re, string\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dedicated-tutorial",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "vectorizer = SentenceTransformer('model/all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "patient-wallpaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим приветствия\n",
    "def del_intro(text):\n",
    "\n",
    "        alphanum = r'a-zа-яёе0-9'\n",
    "        alphabet = r'a-zа-яёе'\n",
    "\n",
    "        del_from_sentence = ['добрый день', 'добрый вечер', 'доброе утро', 'просьба подсказать', 'доброй ночи', 'доброе время суток', 'доброго времени суток', 'доброго времени', \\\n",
    "                             'день добрый', 'доброго времени', 'доброго дня', 'вечер добрый', 'утро доброе', 'подскажите пожалуйста', 'подскажите, пожалуйста', 'подскажите,пожалуйста', \\\n",
    "                             'скажите пожалуйста', 'скажите, пожалуйста', 'скажите,пожалуйста']\n",
    "\n",
    "        add2stop_words = ['подскажите', 'подсказать', 'пожалуйста', 'здравствуйте', 'здраствуйте', 'здравствуй', 'пожалуйста', 'приветствую', 'привет']\n",
    "\n",
    "        stop_words = del_from_sentence + add2stop_words\n",
    "\n",
    "        text = str(text).lower()\n",
    "        for word in stop_words:\n",
    "                if word in text:\n",
    "                        # print(word)\n",
    "                        text = re.sub(word, ' ', text)\n",
    "        obj = re.match(r'[\\d+\\W+]{,}', text)\n",
    "        text = text[0 if obj is None else len(obj.group(0)):]\n",
    "        text = re.sub(r'[\\s+]', ' ', text)\n",
    "        text = re.sub(r'([a-zа-яёе])\\1{2,}', r'\\1\\1', text)  # aaaaa -> aa\n",
    "        text = re.sub(r'([^a-zа-яёе0-9])\\1{1,}', r'\\1', text)  # )))) -> )\n",
    "        text = re.sub(r'([^0-9]|^)([%s]+)([^0-9]|$)' % string.punctuation, r'\\1 \\2 \\3', text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "magnetic-huntington",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(138695, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загрузим датасет\n",
    "df = pd.read_excel('data/train_data.xlsx')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "finished-driver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['intent_id', 'domain', 'labeled', 'message', 'mode', 'intent'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "meaning-respondent",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "№ intents: 707\n"
     ]
    }
   ],
   "source": [
    "# сгруппируем по тематике и посчитаем кол-во примеров\n",
    "df_grouped = df.groupby('intent').agg({'intent_id':'count'}).reset_index()\n",
    "df_grouped.columns=['intent', 'cnt']#.sort_values(ascending=True)\n",
    "df_grouped.sort_values(by='cnt', ascending=False, inplace=True)\n",
    "print('№ intents:', df_grouped.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "precise-involvement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     707.000000\n",
       "mean      196.173975\n",
       "std       348.631691\n",
       "min         1.000000\n",
       "25%        34.000000\n",
       "50%        65.000000\n",
       "75%       196.500000\n",
       "max      3600.000000\n",
       "Name: cnt, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмотрим на распределение кол-ва примеров на тематиках\n",
    "df_grouped['cnt'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "atomic-electron",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# выведем кол-во примеров на тематику до 10го процентиля по выборке\n",
    "np.percentile(df_grouped['cnt'].tolist(), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "under-medicaid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# выведем кол-во тематик, в которых кол-во примеров ниже 10го процентиля по выборке\n",
    "df_grouped[df_grouped['cnt']<=np.percentile(df_grouped['cnt'].tolist(), 10)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonprofit-flour",
   "metadata": {},
   "source": [
    "10% от выборки - тематики, с количеством примеров менее 15. \n",
    "Тк в данном примере не предусматривается апсемплинг, имеем ввиду, что точность на данных тематиках опустит общий скор вниз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "increasing-findings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# выполним препроцессинг\n",
    "df['preprocessed'] = df['message'].apply(del_intro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-territory",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "institutional-redhead",
   "metadata": {},
   "source": [
    "### векторизуем с помощью Sentence Embedding модели на архитектуре трансформеров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "wireless-central",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 53s, sys: 9min 21s, total: 18min 15s\n",
      "Wall time: 8min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectors = vectorizer.encode(df['preprocessed'].tolist())\n",
    "vectors.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exceptional-grant",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "color-buying",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13\n",
       "1    13\n",
       "2    13\n",
       "3    14\n",
       "4    14\n",
       "Name: target, dtype: int16"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# подготовим классы\n",
    "df['target'] = df['intent'].astype('category').cat.codes\n",
    "df['target'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "electrical-aberdeen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "707"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# создадим словарь отношений номера класса к названию тематик\n",
    "intent2target = {}\n",
    "for i, row in df[['intent', 'target']].drop_duplicates().iterrows():\n",
    "    intent2target[row['target']] = row['intent']\n",
    "\n",
    "len(intent2target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "involved-burke",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# преобразуем в категориальный вид таргет\n",
    "y_cat = to_categorical(df['target'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "national-citizenship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes: x_train, x_test, y_train, y_test: (124825, 768) (13870, 768) (124825, 707) (13870, 707)\n"
     ]
    }
   ],
   "source": [
    "# разделим на тренировочную и тестовую выборки\n",
    "x_train, x_test, y_train, y_test = train_test_split(vectors, y_cat, test_size=0.1, random_state=777, shuffle=True)\n",
    "print('shapes: x_train, x_test, y_train, y_test:', x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-scoop",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-smoke",
   "metadata": {},
   "source": [
    "### обучим модель нейросети на эмбеддингах модели all-mpnet-base-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ambient-nowhere",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00681733, -0.04985548,  0.04259589, -0.01603217,  0.04686847,\n",
       "       -0.00667169, -0.01182848,  0.01598987, -0.00153588,  0.00027185,\n",
       "        0.02500646, -0.02011023,  0.00300912,  0.02421119,  0.03337623,\n",
       "       -0.03482555, -0.02754534,  0.01827239, -0.01404077,  0.03275978],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0][:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "conditional-bahrain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 512)               393728    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense3 (Dense)               (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_out (Dense)            (None, 707)               362691    \n",
      "=================================================================\n",
      "Total params: 1,281,731\n",
      "Trainable params: 1,281,731\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp_ = Input(shape=(x_train.shape[1],))\n",
    "x = Dense(512, activation='linear', name='dense1')(inp_)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(512, activation='linear', name='dense2')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(512, activation='linear', name='dense3')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "out = Dense(y_train.shape[1], activation='softmax', name='dense_out')(x)\n",
    "model = Model(inp_, out)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
    "             loss='categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# model.load_weights('model/weights/model_weights_0.001.hdf5')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "swedish-hacker",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 124825 samples, validate on 13870 samples\n",
      "Epoch 1/25\n",
      "124825/124825 [==============================] - 4s 31us/step - loss: 0.5540 - accuracy: 0.8322 - val_loss: 0.8051 - val_accuracy: 0.7973\n",
      "Epoch 2/25\n",
      "124825/124825 [==============================] - 3s 25us/step - loss: 0.5443 - accuracy: 0.8337 - val_loss: 0.8035 - val_accuracy: 0.7973\n",
      "Epoch 3/25\n",
      "124825/124825 [==============================] - 3s 23us/step - loss: 0.5393 - accuracy: 0.8340 - val_loss: 0.8019 - val_accuracy: 0.7985\n",
      "Epoch 4/25\n",
      "124825/124825 [==============================] - 3s 26us/step - loss: 0.5398 - accuracy: 0.8356 - val_loss: 0.7987 - val_accuracy: 0.7980\n",
      "Epoch 5/25\n",
      "124825/124825 [==============================] - 3s 25us/step - loss: 0.5391 - accuracy: 0.8354 - val_loss: 0.7990 - val_accuracy: 0.7987\n",
      "Epoch 6/25\n",
      "124825/124825 [==============================] - 3s 24us/step - loss: 0.5372 - accuracy: 0.8359 - val_loss: 0.7975 - val_accuracy: 0.7987\n",
      "Epoch 7/25\n",
      "124825/124825 [==============================] - 3s 23us/step - loss: 0.5342 - accuracy: 0.8372 - val_loss: 0.7991 - val_accuracy: 0.7994\n",
      "Epoch 8/25\n",
      "124825/124825 [==============================] - 3s 23us/step - loss: 0.5348 - accuracy: 0.8361 - val_loss: 0.7981 - val_accuracy: 0.7994\n",
      "Epoch 9/25\n",
      "124825/124825 [==============================] - 3s 24us/step - loss: 0.5337 - accuracy: 0.8364 - val_loss: 0.7986 - val_accuracy: 0.7987\n",
      "Epoch 10/25\n",
      "124825/124825 [==============================] - 3s 26us/step - loss: 0.5315 - accuracy: 0.8379 - val_loss: 0.7966 - val_accuracy: 0.7983\n",
      "Epoch 11/25\n",
      "124825/124825 [==============================] - 3s 26us/step - loss: 0.5374 - accuracy: 0.8343 - val_loss: 0.7972 - val_accuracy: 0.7996\n",
      "Epoch 12/25\n",
      "124825/124825 [==============================] - 3s 23us/step - loss: 0.5293 - accuracy: 0.8380 - val_loss: 0.7976 - val_accuracy: 0.7994\n",
      "Epoch 13/25\n",
      "124825/124825 [==============================] - 3s 23us/step - loss: 0.5298 - accuracy: 0.8369 - val_loss: 0.7970 - val_accuracy: 0.7991\n",
      "Epoch 14/25\n",
      "124825/124825 [==============================] - 3s 23us/step - loss: 0.5303 - accuracy: 0.8374 - val_loss: 0.7955 - val_accuracy: 0.8004\n",
      "Epoch 15/25\n",
      "124825/124825 [==============================] - 3s 24us/step - loss: 0.5300 - accuracy: 0.8367 - val_loss: 0.7986 - val_accuracy: 0.7978\n",
      "Epoch 16/25\n",
      "124825/124825 [==============================] - 3s 24us/step - loss: 0.5289 - accuracy: 0.8372 - val_loss: 0.7993 - val_accuracy: 0.7996\n",
      "Epoch 17/25\n",
      "124825/124825 [==============================] - 3s 24us/step - loss: 0.5286 - accuracy: 0.8379 - val_loss: 0.7992 - val_accuracy: 0.7995\n",
      "Epoch 18/25\n",
      "124825/124825 [==============================] - 3s 23us/step - loss: 0.5267 - accuracy: 0.8380 - val_loss: 0.7981 - val_accuracy: 0.8006\n",
      "Epoch 19/25\n",
      "124825/124825 [==============================] - 3s 21us/step - loss: 0.5239 - accuracy: 0.8387 - val_loss: 0.7982 - val_accuracy: 0.7994\n",
      "Epoch 20/25\n",
      "124825/124825 [==============================] - 3s 21us/step - loss: 0.5272 - accuracy: 0.8375 - val_loss: 0.7986 - val_accuracy: 0.7984\n",
      "Epoch 21/25\n",
      "124825/124825 [==============================] - 3s 23us/step - loss: 0.5264 - accuracy: 0.8375 - val_loss: 0.8027 - val_accuracy: 0.7983\n",
      "Epoch 22/25\n",
      "124825/124825 [==============================] - 3s 21us/step - loss: 0.5235 - accuracy: 0.8389 - val_loss: 0.8009 - val_accuracy: 0.7994\n",
      "Epoch 23/25\n",
      "124825/124825 [==============================] - 3s 21us/step - loss: 0.5286 - accuracy: 0.8381 - val_loss: 0.7985 - val_accuracy: 0.8012\n",
      "Epoch 24/25\n",
      "124825/124825 [==============================] - 3s 21us/step - loss: 0.5237 - accuracy: 0.8387 - val_loss: 0.7985 - val_accuracy: 0.8000\n",
      "Epoch 25/25\n",
      "124825/124825 [==============================] - 3s 22us/step - loss: 0.5227 - accuracy: 0.8390 - val_loss: 0.7985 - val_accuracy: 0.7980\n"
     ]
    }
   ],
   "source": [
    "r = model.fit(x_train,\n",
    "             y_train,\n",
    "             epochs=25,\n",
    "             batch_size=2048,\n",
    "             validation_data=(x_test, y_test),\n",
    "             verbose=1,\n",
    "             callbacks=[ModelCheckpoint('model/weights/model_weights_0.0001.hdf5',\n",
    "                                    monitor='val_accuracy',\n",
    "                                    mode='max',\n",
    "                                    save_weights_only=True,\n",
    "                                    save_best_only=True,\n",
    "                                    verbose=0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriented-louisville",
   "metadata": {},
   "source": [
    "посмотрим на результат дообучения модели на разных lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "olympic-welcome",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13870/13870 [==============================] - 1s 93us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.1857967839278845, 0.7187454700469971]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('model/weights/model_weights_0.01.hdf5')\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "impaired-sender",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13870/13870 [==============================] - 1s 95us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.8256376277394835, 0.7938716411590576]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('model/weights/model_weights_0.001.hdf5')\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "mechanical-prisoner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13870/13870 [==============================] - 1s 97us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7985499518847586, 0.8011535406112671]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('model/weights/model_weights_0.0001.hdf5')\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-seattle",
   "metadata": {},
   "source": [
    "------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
